![image](https://github.com/Bekalu-t/Fine-Tuning-BERT-for-Sentiment-Analysis-Towards-Bitcoin/assets/174369527/da861fb6-5d7f-42db-8b38-ecb239ef7baf)

# Fine-Tuning BERT for Sentiment Analysis Towards Bitcoin

## Authors
- Zemedkun Abebe
- Bekalu Tamrat

## Date
- \today

## Abstract
This report documents the process of fine-tuning a BERT model for sentiment analysis on a dataset of tweets. The model was trained and evaluated using the Hugging Face Transformers library, and a simple Streamlit web application was created to deploy the model for real-time sentiment prediction.

## Introduction
Sentiment analysis is a crucial task in natural language processing that aims to determine the sentiment expressed in textual data, such as tweets, reviews, or comments. Understanding sentiment can provide valuable insights into public opinion, customer feedback, and social trends. This report explores the application of BERT (Bidirectional Encoder Representations from Transformers), a state-of-the-art transformer model, for sentiment analysis on a dataset sourced from `sds.csv`. The goal is to classify tweets into three sentiment categories: Negative, Neutral, and Positive, using advanced deep learning techniques.
